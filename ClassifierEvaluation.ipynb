{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Classifier Evaluation Example\n",
    "\n",
    "In this example we evaluate the multi-class classifier we created in the traoning example.\n",
    "We will use the same approach to create and read the data.  However, the data file used\n",
    "for evaluation will be newly generated, guaranteeing that we are not using any data\n",
    "used in the training.\n",
    "\n",
    "As a reminder: the function `truth_labels_unit_circle` in the `dataprovider` module \n",
    "defines three classes for the (x1, x2) tuples:\n",
    "\n",
    " 1. points outside the unit circle `r = sqrt(x1*x1 + x2*x2) >= 1` (this is considered 'background')\n",
    " 2. points in the unit circle with `x2 <= 0.0` (this is considered 'signal 1')\n",
    " 3. points in the unit circle with `x2 > 0.0` (this is considered 'signal 2')\n",
    " \n",
    "The truth labels are therefore one-hot vectors of dimension 3.  The `dataprovider` \n",
    "dynamically generates the truth labels using the above definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Setup\n",
    "Import the required modules and make sure our (and only our!) modules are reloaded \n",
    "before code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%aimport dataprovider, classification\n",
    "%autoreload 1\n",
    "\n",
    "# framework modules\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# our modules\n",
    "import dataprovider as dp\n",
    "import classification as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": "#### Data Sets\nHere we generate a binary file with a data set for evaluation and provide the corresponding \nPyTorch data set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "data_file_path = './evaluation_data.bin'\ndp.generate_data(data_file_path, force=False)\nnum_events = 20000\nevaluation_events = dp.events(data_file_path, evt_max=num_events)\nevaluation_dataset = cl.LabeledDataset(evaluation_events,\n                                     var_generator=dp.event_to_values,\n                                     label_generator=dp.truth_labels_unit_circle)\nxs, ys_true = evaluation_dataset[:]"
  },
  {
   "cell_type": "markdown",
   "source": "#### Run the Trained Classifier\n\nWe construct the classifier and load the weights produced in Training Example 1.\nNext we run the classifier on the entire dataset. Not that we do this with auto \ngradient following turned off.  This is faster and we do not need the gradient\ntree for inference.",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "classifier_nn = cl.ClassifierNN(layout=(2, 5, 7, 3))\nweight_file_path = 'classifier_weights_example1_2x5x7x3.pt'\nclassifier_nn.load_state_dict(torch.load(weight_file_path))\nclassifier_nn.eval()\nwith torch.no_grad():\n    ys_pred = classifier_nn(xs)\n    \nprint('Classfified', ys_pred.size()[0], 'events into', ys_pred.size()[1], 'classes.')\n    ",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### ROC Curves\nROC (Receiver Operating Characteristic) curves are the ML community's version\nof the background suppression versus efficiency plots we are used to in HEP.\nIn fact they are almost exactly the same.\n\nIn a ROC curve the the *true positive rate* if plotted versus the *false positive rate*.\n\nThe *true positive rate* is the fraction of true target class instances identified as such, ie. \nthe *efficiency*.\n\nThe *false positive rate* is the fraction of true background events identified as such, ie.\n *1 - background suppression*.\n\nThe rates are computed by scanning the classifier output \nin the interval `[0, 1]`. We do not have to write the code for this \nscan ourselves.  Instead we use the `metric` facilities of `sklearn`.\n\nAUC is simply the area under the ROC curve in the interval `[0, 1]`. \nAn AUC of 1 is ideal.",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "plot_labels = {0 : 'background', 1 : 'signal 1', 2: 'signal 2'}\nfpr, tpr, thresh, area = dict(), dict(), dict(), dict()\nfor i in range(3):\n    fpr[i], tpr[i], thresh[i] = roc_curve(ys_true[:,i], ys_pred[:,i])\n    area[i] = auc(fpr[i], tpr[i])\n\nplt.figure()\nplt.title('ROC Curves')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nfor i in range(3):\n    plt.plot(fpr[i], tpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\n\nplt.plot(thresh[2][1:], thresh[2][1:], '--', label='threshold')\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.title('ROC Curves Zoom')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.xlim((-0.01, 0.2))\nplt.ylim((0.8, 1.01))\nfor i in range(3):\n    plt.plot(fpr[i], tpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\nplt.legend()\nplt.show()",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Background Suppression Versus Efficiency\n\nWe now plot the same data in the more familiar \nfashion of background suppression versus efficiency.\n\nHere (and in the ROC section above) the *background* is the collection of events that\nare a different class instance than the class label considered. For example, the background for \n*signal 1* is all events where the true class is either *background* or *signal 2*.",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "eff = tpr\n\nplt.figure()\nplt.title('Background Supp. vs. Efficiency')\nplt.xlabel('Efficiency')\nplt.ylabel('Background Suppression')\nfor i in range(3):\n    plt.plot(eff[i], 1.0 - fpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\nplt.plot(thresh[2][1:], 1.0 - thresh[2][1:], '--', label='threshold')\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.title('Background Supp. vs. Efficiency Zoom')\nplt.xlabel('Efficiency')\nplt.ylabel('Background Suppression')\nplt.xlim((0.8, 1.01))\nplt.ylim((0.8, 1.01))\nfor i in range(3):\n    plt.plot(eff[i], 1.0 - fpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\nplt.legend()\nplt.show()\n",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}